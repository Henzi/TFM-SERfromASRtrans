{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LXoRd3n8nUdl"
   },
   "outputs": [],
   "source": [
    "path_dataset ='/home/marrakchi/TFM/TFM_env/Datasets/ExKaldiASRDatasetFormat/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "2PXQOtUznUdx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Kaldi root directory was not found in system PATH. You can appoint it:\n",
      "exkaldi.info.reset_kaldi_root( yourPath )\n",
      "If not, ERROR will occur when implementing some core functions.\n"
     ]
    }
   ],
   "source": [
    "# Systems Libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "# For audio processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython as ipd\n",
    "from IPython.display import display, HTML # For displaying tables\n",
    "\n",
    "# For data processing\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# For visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For text processing\n",
    "import string\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Import exkaldi package\n",
    "import exkaldi\n",
    "exkaldi.info.reset_kaldi_root('/kaldi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExKaldiInfo(version='1.3.5.4', major='1', minor='3', patch='5', upload='4')\n",
      "Kaldi(version='5.5', major='5', minor='5')\n",
      "/kaldi\n"
     ]
    }
   ],
   "source": [
    "# ExKaldi Configuration\n",
    "ExKaldiInfo = exkaldi.info\n",
    "print(ExKaldiInfo)\n",
    "print(ExKaldiInfo.KALDI)\n",
    "print(ExKaldiInfo.KALDI_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Ensuring that GPU are detected/available and ready to use\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<exkaldi.decode.graph.LexiconBank object at 0x7ffa6bccce48>\n"
     ]
    }
   ],
   "source": [
    "# Load lexicon\n",
    "lexicons = exkaldi.load_lex(os.path.join(path_dataset, \"dict\", \"lexicons.lex\"))\n",
    "print(lexicons)\n",
    "# Load transcriptions\n",
    "trans = exkaldi.load_transcription(os.path.join(path_dataset,\"text\"))\n",
    "trainTrans = exkaldi.load_transcription(os.path.join(path_dataset,'data/train',\"text\"))\n",
    "valTrans = exkaldi.load_transcription(os.path.join(path_dataset,'data/val',\"text\"))\n",
    "testTrans = exkaldi.load_transcription(os.path.join(path_dataset,'data/test',\"text\"))\n",
    "# Load wavScp\n",
    "wavScp = exkaldi.load_list_table(os.path.join(path_dataset,\"wav.scp\") )\n",
    "wavScp_train = exkaldi.load_list_table(os.path.join(path_dataset,'data/train',\"wav.scp\") )\n",
    "wavScp_val = exkaldi.load_list_table(os.path.join(path_dataset,'data/val',\"wav.scp\") )\n",
    "wavScp_test = exkaldi.load_list_table(os.path.join(path_dataset,'data/test',\"wav.scp\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate ARPA language model done.\n"
     ]
    }
   ],
   "source": [
    "## Train N-Grams language model\n",
    "# 1. Train a LM.\n",
    "# We have trained 2,3,4 grams model with both srilm and kenlm and chose the best one, which is 3-grams model back kenlm.\n",
    "# So we directly train this one.\n",
    "exkaldi.lm.train_ngrams_kenlm(\n",
    "                        lexicons,\n",
    "                        order=3,\n",
    "                        text=trainTrans,  # (exkaldi Transcription object)--> the information of utterance IDs will be omitted automatically.\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"3grams.arpa\"), \n",
    "                        config={\"--discount_fallback\":True,\"-S\":\"20%\"},\n",
    "                    )\n",
    "\n",
    "print(f\"Generate ARPA language model done.\")\n",
    "\n",
    "# First error --> permission denied \n",
    "#    chmod 0775 /home/marrakchi/TFM/TFM_env/exkaldisrc/tools/lmplz\n",
    "# Second error --> error while loading shared libraries: libboost_program_options.so.1.65.1\n",
    "#    SOLUTION --> sudo apt-get install libboost-program-options-dev\n",
    "\n",
    "# ARPA model can be transform to binary format in order to accelerate loading and reduce memory cost.\n",
    "exkaldi.lm.arpa_to_binary(\n",
    "                            arpaFile=os.path.join(path_dataset,\"lm\",f\"3grams.arpa\"),\n",
    "                            outFile=os.path.join(path_dataset,\"lm\",f\"3grams.binary\"),\n",
    "                        )\n",
    "# First error --> permission denied \n",
    "#    chmod 0775 /home/marrakchi/TFM/TFM_env/exkaldisrc/tools/build_binary\n",
    "\n",
    "# Train 2-gram KENLM model\n",
    "exkaldi.lm.train_ngrams_kenlm(\n",
    "                        lexicons,\n",
    "                        order=2,\n",
    "                        text=trainTrans,  # (exkaldi Transcription object)--> the information of utterance IDs will be omitted automatically.\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"2grams.arpa\"), \n",
    "                        config={\"--discount_fallback\":True,\"-S\":\"20%\"},\n",
    "                    )\n",
    "exkaldi.lm.arpa_to_binary(\n",
    "                            arpaFile=os.path.join(path_dataset,\"lm\",f\"2grams.arpa\"),\n",
    "                            outFile=os.path.join(path_dataset,\"lm\",f\"2grams.binary\"),\n",
    "                        )\n",
    "\n",
    "# Train 4-gram KENLM model\n",
    "exkaldi.lm.train_ngrams_kenlm(\n",
    "                        lexicons,\n",
    "                        order=4,\n",
    "                        text=trainTrans,  # (exkaldi Transcription object)--> the information of utterance IDs will be omitted automatically.\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"4grams.arpa\"), \n",
    "                        config={\"--discount_fallback\":True,\"-S\":\"20%\"},\n",
    "                    )\n",
    "exkaldi.lm.arpa_to_binary(\n",
    "                            arpaFile=os.path.join(path_dataset,\"lm\",f\"4grams.arpa\"),\n",
    "                            outFile=os.path.join(path_dataset,\"lm\",f\"4grams.binary\"),\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/marrakchi/TFM/TFM_env/Datasets/ExKaldiASRDatasetFormat/lm/6grams.binary'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train 5-gram KENLM model\n",
    "exkaldi.lm.train_ngrams_kenlm(\n",
    "                        lexicons,\n",
    "                        order=5,\n",
    "                        text=trainTrans,  # (exkaldi Transcription object)--> the information of utterance IDs will be omitted automatically.\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"5grams.arpa\"), \n",
    "                        config={\"--discount_fallback\":True,\"-S\":\"20%\"},\n",
    "                    )\n",
    "exkaldi.lm.arpa_to_binary(\n",
    "                            arpaFile=os.path.join(path_dataset,\"lm\",f\"5grams.arpa\"),\n",
    "                            outFile=os.path.join(path_dataset,\"lm\",f\"5grams.binary\"),\n",
    "                        )\n",
    "\n",
    "# Train 6-gram KENLM model\n",
    "exkaldi.lm.train_ngrams_kenlm(\n",
    "                        lexicons,\n",
    "                        order=6,\n",
    "                        text=trainTrans,  # (exkaldi Transcription object)--> the information of utterance IDs will be omitted automatically.\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"6grams.arpa\"), \n",
    "                        config={\"--discount_fallback\":True,\"-S\":\"20%\"},\n",
    "                    )\n",
    "exkaldi.lm.arpa_to_binary(\n",
    "                            arpaFile=os.path.join(path_dataset,\"lm\",f\"6grams.arpa\"),\n",
    "                            outFile=os.path.join(path_dataset,\"lm\",f\"6grams.binary\"),\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------3-GRAMS--------------------------------------------------------------\n",
      "NgramInfo(order=3, path=\"b'/home/marrakchi/TFM/TFM_env/Datasets/ExKaldiASRDatasetFormat/lm/3grams.binary'\")\n",
      "\n",
      "The weighted average perplexity of this model is: PPL(prob=-817979.52, sentences=24756, words=291975, ppl=382.44, ppl1=633.2).\n",
      "\n",
      "Mean Score -->  -33.04166745975804\n",
      "\n",
      "Mean Score by length of sentence--> -41.17497238319086\n",
      "\n",
      "----------------------------------2-GRAMS--------------------------------------------------------------\n",
      "NgramInfo(order=2, path=\"b'/home/marrakchi/TFM/TFM_env/Datasets/ExKaldiASRDatasetFormat/lm/2grams.binary'\")\n",
      "\n",
      "The weighted average perplexity of this model is: PPL(prob=-839317.55, sentences=24756, words=291975, ppl=446.62, ppl1=749.24).\n",
      "\n",
      "Mean Score -->  -33.90360111887071\n",
      "\n",
      "Mean Score by length of sentence--> -42.37599998133139\n",
      "\n",
      "----------------------------------4-GRAMS--------------------------------------------------------------\n",
      "NgramInfo(order=4, path=\"b'/home/marrakchi/TFM/TFM_env/Datasets/ExKaldiASRDatasetFormat/lm/4grams.binary'\")\n",
      "\n",
      "The weighted average perplexity of this model is: PPL(prob=-811500.4, sentences=24756, words=291975, ppl=364.85, ppl1=601.66).\n",
      "\n",
      "Mean Score -->  -32.77994845818387\n",
      "\n",
      "Mean Score by length of sentence--> -40.78288894117673\n"
     ]
    }
   ],
   "source": [
    "# 2. Test the model by computing the perplexity.\n",
    "\n",
    "# initialize a Python KenLM n-grams object\n",
    "print('\\n----------------------------------3-GRAMS--------------------------------------------------------------')\n",
    "model = exkaldi.load_ngrams( os.path.join(path_dataset,\"lm\",f\"3grams.binary\") )\n",
    "print(model.info)\n",
    "perScore = model.perplexity(testTrans)\n",
    "print(f\"\\nThe weighted average perplexity of this model is: {perScore}.\")\n",
    "# 3. score\n",
    "score = model.score(testTrans)\n",
    "print('\\nMean Score --> ', score.mean())\n",
    "print('\\nMean Score by length of sentence-->', score.mean( weight= testTrans.sentence_length() ))\n",
    "print('\\n----------------------------------2-GRAMS--------------------------------------------------------------')\n",
    "model = exkaldi.load_ngrams( os.path.join(path_dataset,\"lm\",f\"2grams.binary\") )\n",
    "print(model.info)\n",
    "perScore = model.perplexity(testTrans)\n",
    "score = model.score(testTrans)\n",
    "print(f\"\\nThe weighted average perplexity of this model is: {perScore}.\")\n",
    "print('\\nMean Score --> ', score.mean())\n",
    "print('\\nMean Score by length of sentence-->', score.mean( weight= testTrans.sentence_length() ))\n",
    "print('\\n----------------------------------4-GRAMS--------------------------------------------------------------')\n",
    "model = exkaldi.load_ngrams( os.path.join(path_dataset,\"lm\",f\"4grams.binary\") )\n",
    "print(model.info)\n",
    "perScore = model.perplexity(testTrans)\n",
    "score = model.score(testTrans)\n",
    "print(f\"\\nThe weighted average perplexity of this model is: {perScore}.\")\n",
    "print('\\nMean Score --> ', score.mean())\n",
    "print('\\nMean Score by length of sentence-->', score.mean( weight= testTrans.sentence_length() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------5-GRAMS--------------------------------------------------------------\n",
      "NgramInfo(order=5, path=\"b'/home/marrakchi/TFM/TFM_env/Datasets/ExKaldiASRDatasetFormat/lm/5grams.binary'\")\n",
      "\n",
      "The weighted average perplexity of this model is: PPL(prob=-810374.96, sentences=24756, words=291975, ppl=361.88, ppl1=596.34).\n",
      "\n",
      "Mean Score -->  -32.73448707470314\n",
      "\n",
      "Mean Score by length of sentence--> -40.711886746512704\n",
      "\n",
      "----------------------------------6-GRAMS--------------------------------------------------------------\n",
      "NgramInfo(order=6, path=\"b'/home/marrakchi/TFM/TFM_env/Datasets/ExKaldiASRDatasetFormat/lm/6grams.binary'\")\n",
      "\n",
      "The weighted average perplexity of this model is: PPL(prob=-810391.23, sentences=24756, words=291975, ppl=361.92, ppl1=596.42).\n",
      "\n",
      "Mean Score -->  -32.73514416969387\n",
      "\n",
      "Mean Score by length of sentence--> -40.711357113193095\n"
     ]
    }
   ],
   "source": [
    "print('\\n----------------------------------5-GRAMS--------------------------------------------------------------')\n",
    "model = exkaldi.load_ngrams( os.path.join(path_dataset,\"lm\",f\"5grams.binary\") )\n",
    "print(model.info)\n",
    "perScore = model.perplexity(testTrans)\n",
    "print(f\"\\nThe weighted average perplexity of this model is: {perScore}.\")\n",
    "# 3. score\n",
    "score = model.score(testTrans)\n",
    "print('\\nMean Score --> ', score.mean())\n",
    "print('\\nMean Score by length of sentence-->', score.mean( weight= testTrans.sentence_length() ))\n",
    "print('\\n----------------------------------6-GRAMS--------------------------------------------------------------')\n",
    "model = exkaldi.load_ngrams( os.path.join(path_dataset,\"lm\",f\"6grams.binary\") )\n",
    "print(model.info)\n",
    "perScore = model.perplexity(testTrans)\n",
    "score = model.score(testTrans)\n",
    "print(f\"\\nThe weighted average perplexity of this model is: {perScore}.\")\n",
    "print('\\nMean Score --> ', score.mean())\n",
    "print('\\nMean Score by length of sentence-->', score.mean( weight= testTrans.sentence_length() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Grammar fst done.\n",
      "Compose LG fst done.\n"
     ]
    }
   ],
   "source": [
    "# ------- Make Grammar fst ------\n",
    "exkaldi.decode.graph.make_G(\n",
    "                        lexicons, \n",
    "                        arpaFile=os.path.join(path_dataset,\"lm\",f\"5grams.arpa\"),\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"G.5.fst\"), \n",
    "                        order=4\n",
    "                    )\n",
    "print(f\"Make Grammar fst done.\")\n",
    "\n",
    "# ------- Compose LG fst for futher use ------\n",
    "exkaldi.decode.graph.compose_LG(\n",
    "                        LFile=os.path.join(path_dataset,\"dict\",\"L_disambig.fst\"), \n",
    "                        GFile=os.path.join(path_dataset,\"lm\",f\"G.5.fst\"),\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"LG.5.fst\"),\n",
    "                    )\n",
    "print(f\"Compose LG fst done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Train 4-gram SRILM model\n",
    "exkaldi.lm.train_ngrams_srilm(\n",
    "                        lexicons,\n",
    "                        order=4,\n",
    "                        text=trainTrans,  # (exkaldi Transcription object)--> the information of utterance IDs will be omitted automatically.\n",
    "                        outFile=os.path.join(path_dataset,\"lm\",f\"4grams_srilm.arpa\"), \n",
    "                        config={\"--discount_fallback\":True,\"-S\":\"20%\"},\n",
    "                    )\n",
    "exkaldi.lm.arpa_to_binary(\n",
    "                            arpaFile=os.path.join(path_dataset,\"lm\",f\"4grams_srilm.arpa\"),\n",
    "                            outFile=os.path.join(path_dataset,\"lm\",f\"4grams_srilm.binary\"),\n",
    "                        )\n",
    "model = exkaldi.load_ngrams( os.path.join(path_dataset,\"lm\",f\"4grams_srilm.binary\") )\n",
    "print(model.info)\n",
    "perScore = model.perplexity(testTrans)\n",
    "score = model.score(testTrans)\n",
    "print(f\"\\nThe weighted average perplexity of this model is: {perScore}.\")\n",
    "print('\\nMean Score --> ', score.mean())\n",
    "print('\\nMean Score by length of sentence-->', score.mean( weight= testTrans.sentence_length() ))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
